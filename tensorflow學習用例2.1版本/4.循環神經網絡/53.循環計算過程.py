#字母Ay:入aAy出b, 入bAy出c, 入cAy出d, 入dAy出e, 入eAy出a
#神Wj的入都是底,所有我先把abcde五字母用底直硎境
# 用岽a(one-hot)λa如下:
# a 100000
# b 010000
# c 000100
# d 000010
# e 000001

##################################################################算Y果和^程↓↓↓↓↓↓↓↓↓↓↓↓↓↓
# yt=[0.02, 0.02, 0.91, 0.03, 0.02 ]
# ↑
# ↑ by=[0.0, 0.1, 0.4, -0.7, 0.1]
# ↑ w(hy)=[[-1.7,0.7,-1.7,1.7,0.7], [-1.6,-1.6,0.7,1.3,1.4], [-1.4,1.9,1.2,1.7,-1.9]]
# ↑
# ht=[-0.9, 0.8, 0.7]   w(hh)=[[-0.9,-0.2,-0.4], [-0.3,0.9,0.2], [0.4,0.3,0.9]]
# ↑
# ↑ w(xh)=[[0.5,-1.7,1.7], [-2.3,0.8,1.1], [1.3,1.7,1.4], [0.3,0.8,-1.1], [-1.8,-2.0,-1.0]]
# ↑ bh=[0.5, 0.3, -0.2]
# ↑
# xt

# # h(t) = tanh( ( x(t)*w(xh) ) + ( h(t-1)*w(hh) ) + bh )
#        = tanh([-2.3 0.8 1.1] + 0 + [0.5 0.3 -0.2]) #上一r刻也就是最_始rwB信息等於0,所以加上0
#        = tanh[-1.8 1.1 0.9]
#        = [-0.9 0.8 0.7] #得到前r刻的B信息h(t) #w存ΦB信息被刷新[-0.9 0.8 0.7],@^程你可以理解槟X中的因楫前入的事物而更新了

# # y(t) = softmax((h(t) * w(hy)) + by) #y(t)就是把提取到的rg信息,通^全B接M行ReAy的^程,是整Wj的出
#        = softmax([-0.7 -0.6 2.9 0.7 -0.8] + [0.0, 0.1, 0.4, -0.7, 0.1])
#        = softmax([-0.7 -0.5 3.3 0.0 -0.7])
#        = [0.02 0.02 0.91 0.03 0.02] #模型J橛91%的可能性出字母c